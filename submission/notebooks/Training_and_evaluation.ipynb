{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Training and evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0e3c809"
      },
      "source": [
        "# Training a Quantized NN for Modulation Classification\n",
        "**Team Name : Team Velocity**\n",
        "\n",
        "**Team Players : Aakash Agarwal, Satish Kumar, Neeraj Varshney.**\n",
        "\n",
        "**Team Mentor: Prof. Rajarshi Mahapatra**\n",
        "\n",
        "This notebook serves as our submission for the [Lightning-Fast Modulation Classification with Hardware-Efficient Neural Networks](http://bit.ly/brevitas-radioml-challenge-21) problem statement of the [**ITU AI/ML in 5G Challenge**](https://aiforgood.itu.int/ai-ml-in-5g-challenge/).\n",
        "We have shown how to create, train, and evaluate the quantized CNN model.\n",
        "\n",
        "## Outline\n",
        "* [Load the RadioML 2018 Dataset](#load_dataset)\n",
        "* [Our model definition](#define_model)\n",
        "    * [Train the Model from Scratch](#train_model)\n",
        "    * [**Alternatively:** Load Pre-Trained Parameters](#load_trained_model)\n",
        "    * [Prune the model](#prune)\n",
        "* [Evaluate the Accuracy](#evaluate_accuracy)\n",
        "* [Evaluate the Inference Cost](#evaluate_inference_cost)"
      ],
      "id": "c0e3c809"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42a2ea3a"
      },
      "source": [
        "# Import some general modules\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ],
      "id": "42a2ea3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77183fdb"
      },
      "source": [
        "# Select which GPU to use (if available)\n",
        "gpu = 0\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.device(gpu)\n",
        "    print(\"Using GPU %d\" % gpu)\n",
        "else:\n",
        "    gpu = None\n",
        "    print(\"Using CPU only\")"
      ],
      "id": "77183fdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f5f6ada"
      },
      "source": [
        "# The RadioML 2018 Dataset <a id='load_dataset'></a>\n",
        "\n",
        "The dataset comes in hdf5 format and exhibits the following structure:\n",
        "- 24 modulations\n",
        "- 26 SNRs per modulation (-20 dB through +30 dB in steps of 2)\n",
        "- 4096 frames per modulation-SNR combination\n",
        "- 1024 complex time-series samples per frame\n",
        "- Samples as floating point in-phase and quadrature (I/Q) components, resulting in a (1024,2) frame shape\n",
        "- 2.555.904 frames in total\n",
        " \n",
        "\n",
        "## Download\n",
        "The dataset is available here: **https://opendata.deepsig.io/datasets/2018.01/2018.01.OSC.0001_1024x2M.h5.tar.gz**\n",
        "\n",
        "Since access requires a (straightforward) registration, you must download and extract it manually. It measures about 18 GiB in size (20 GiB uncompressed).\n",
        "\n",
        "To access it from within this container, you can place it:\n",
        "- A) Under the submission directory you launched this notebook from, which is mounted under \"/workspace/submission\".\n",
        "- B) Anywhere, then set the environment variable `DATASET_DIR` before launching \"run_docker.sh\" to mount it under \"/workspace/dataset\".\n",
        "\n",
        "You might notice that the dataset comes with a \"classes.txt\" file containing the alleged modulation labels. However, you should disregard the ordering of these labels due to a known issue ([github.com/radioML/dataset/issues/25](http://github.com/radioML/dataset/issues/25)). This notebook uses the corrected labels throughout.\n",
        "\n",
        "In the following, we create the data loader and can inspect some frames to get an idea what the input data looks like."
      ],
      "id": "1f5f6ada"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9282100d"
      },
      "source": [
        "# Check if dataset is present\n",
        "import os.path\n",
        "dataset_path = \"/workspace/submission/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
        "os.path.isfile(dataset_path)"
      ],
      "id": "9282100d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9b13733"
      },
      "source": [
        "# Prepare data loader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "\n",
        "class radioml_18_dataset(Dataset):\n",
        "    def __init__(self, dataset_path):\n",
        "        super(radioml_18_dataset, self).__init__()\n",
        "        h5_file = h5py.File(dataset_path,'r')\n",
        "        self.data = h5_file['X']\n",
        "        self.mod = np.argmax(h5_file['Y'], axis=1) # comes in one-hot encoding\n",
        "        self.snr = h5_file['Z'][:,0]\n",
        "        self.len = self.data.shape[0]\n",
        "\n",
        "        self.mod_classes = ['OOK','4ASK','8ASK','BPSK','QPSK','8PSK','16PSK','32PSK',\n",
        "        '16APSK','32APSK','64APSK','128APSK','16QAM','32QAM','64QAM','128QAM','256QAM',\n",
        "        'AM-SSB-WC','AM-SSB-SC','AM-DSB-WC','AM-DSB-SC','FM','GMSK','OQPSK']\n",
        "        self.snr_classes = np.arange(-20., 32., 2) # -20dB to 30dB\n",
        "\n",
        "        # do not touch this seed to ensure the prescribed train/test split!\n",
        "        np.random.seed(2018)\n",
        "        train_indices = []\n",
        "        test_indices = []\n",
        "        for mod in range(0, 24): # all modulations (0 to 23)\n",
        "            for snr_idx in range(0, 26): # all SNRs (0 to 25 = -20dB to +30dB)\n",
        "                # 'X' holds frames strictly ordered by modulation and SNR\n",
        "                start_idx = 26*4096*mod + 4096*snr_idx\n",
        "                indices_subclass = list(range(start_idx, start_idx+4096))\n",
        "                \n",
        "                # 90%/10% training/test split, applied evenly for each mod-SNR pair\n",
        "                split = int(np.ceil(0.1 * 4096)) \n",
        "                np.random.shuffle(indices_subclass)\n",
        "                train_indices_subclass = indices_subclass[split:]\n",
        "                test_indices_subclass = indices_subclass[:split]\n",
        "                \n",
        "                # you could train on a subset of the data, e.g. based on the SNR\n",
        "                # here we use all available training samples\n",
        "                if snr_idx >= 0:\n",
        "                    train_indices.extend(train_indices_subclass)\n",
        "                test_indices.extend(test_indices_subclass)\n",
        "                \n",
        "        self.train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "        self.test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # transpose frame into Pytorch channels-first format (NCL = -1,2,1024)\n",
        "        return self.data[idx].transpose(), self.mod[idx], self.snr[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "dataset = radioml_18_dataset(dataset_path)"
      ],
      "id": "d9b13733",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7d7a939"
      },
      "source": [
        "# Inspect a frame\n",
        "mod = 12 # 0 to 23\n",
        "snr_idx = 25 # 0 to 25 = -20dB to +30dB\n",
        "sample = 123 # 0 to 4095\n",
        "#-----------------------#\n",
        "idx = 26*4096*mod + 4096*snr_idx + sample\n",
        "data, mod, snr = dataset.data[idx], dataset.mod[idx], dataset.snr[idx]\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(data)\n",
        "print(\"Modulation: %s, SNR: %.1f dB, Index: %d\" % (dataset.mod_classes[mod], snr, idx))"
      ],
      "id": "e7d7a939",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f0e28f5"
      },
      "source": [
        "# OUR QNN MODEL"
      ],
      "id": "0f0e28f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a78fab1"
      },
      "source": [
        "from torch import nn\n",
        "import brevitas.nn as qnn\n",
        "from brevitas.quant import IntBias\n",
        "from brevitas.inject.enum import ScalingImplType\n",
        "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
        "\n",
        "# Adjustable hyperparameters\n",
        "input_bits = 4\n",
        "a_bits = 5\n",
        "w_bits = 6\n",
        "filters_conv = 64\n",
        "filters_dense = 128\n",
        "\n",
        "# Setting seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "class InputQuantizer(Int8ActPerTensorFloatMinMaxInit):\n",
        "    bit_width = input_bits\n",
        "    min_val = -2.0\n",
        "    max_val = 2.0\n",
        "    scaling_impl_type = ScalingImplType.CONST # Fix the quantization range to [min_val, max_val]\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # Input quantization layer\n",
        "    qnn.QuantHardTanh(act_quant=InputQuantizer),\n",
        "\n",
        "    qnn.QuantConv1d(2, 16, 8, padding=7, weight_bit_width=w_bits, bias=False),\n",
        "    #nn.BatchNorm1d(filters_conv),\n",
        "    qnn.QuantReLU(bit_width=a_bits),\n",
        "    nn.MaxPool1d(2),\n",
        "\n",
        "    qnn.QuantConv1d(16, 24, 8, padding=7, weight_bit_width=w_bits, bias=False),\n",
        "    nn.BatchNorm1d(24),\n",
        "    qnn.QuantReLU(bit_width=a_bits),\n",
        "    nn.MaxPool1d(2),\n",
        "\n",
        "    qnn.QuantConv1d(24, 32, 8, padding=7, weight_bit_width=w_bits, bias=False),\n",
        "    nn.BatchNorm1d(32),\n",
        "    qnn.QuantReLU(bit_width=a_bits),\n",
        "    nn.MaxPool1d(2),\n",
        "\n",
        "    qnn.QuantConv1d(32, 48, 8, padding=7, weight_bit_width=w_bits, bias=False),\n",
        "    nn.BatchNorm1d(48),\n",
        "    qnn.QuantReLU(bit_width=a_bits),\n",
        "    nn.MaxPool1d(2),\n",
        "\n",
        "    qnn.QuantConv1d(48, 64, 8, padding=7, weight_bit_width=w_bits, bias=False),\n",
        "    nn.BatchNorm1d(64),\n",
        "    qnn.QuantReLU(bit_width=a_bits),\n",
        "    nn.MaxPool1d(2),\n",
        "\n",
        "    qnn.QuantConv1d(64, 96, 8, padding=7, weight_bit_width=w_bits, bias=False),\n",
        "    nn.BatchNorm1d(96),\n",
        "    qnn.QuantReLU(bit_width=a_bits),\n",
        "    nn.AvgPool1d(32),\n",
        "   \n",
        "    nn.Flatten(),\n",
        "\n",
        "    qnn.QuantLinear(96, 24, weight_bit_width=w_bits, bias=False),\n",
        "    qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
        "    qnn.QuantLinear(24, 24, weight_bit_width=w_bits, bias=True, bias_quant=IntBias),\n",
        ")"
      ],
      "id": "2a78fab1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33e13718"
      },
      "source": [
        "# Train the QNN from Scratch <a id='train_model'></a>\n",
        "<span style=\"color:red\">Even with GPU acceleration, training will take multiple minutes per epoch!<br>You can skip this section and load a pre-trained model instead: [Load Pre-Trained Parameters](#load_trained_model)</span>\n",
        "\n",
        "First, we define basic train and test functions, which will be called for each training epoch. Training itself follows the usual Pytorch procedures, while Brevitas handles all quantization-specifics automatically in the background."
      ],
      "id": "33e13718"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ef798a"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    losses = []\n",
        "    # ensure model is in training mode\n",
        "    model.train()    \n",
        "\n",
        "    for (inputs, target, snr) in tqdm(train_loader, desc=\"Batches\", leave=False):   \n",
        "        if gpu is not None:\n",
        "            inputs = inputs.cuda()\n",
        "            target = target.cuda()\n",
        "                \n",
        "        # forward pass\n",
        "        output = model(inputs)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # backward pass + run optimizer to update weights\n",
        "        optimizer.zero_grad() \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # keep track of loss value\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "           \n",
        "    return losses\n",
        "\n",
        "def test(model, test_loader):    \n",
        "    # ensure model is in eval mode\n",
        "    model.eval() \n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "   \n",
        "    with torch.no_grad():\n",
        "        for (inputs, target, snr) in test_loader:\n",
        "            if gpu is not None:\n",
        "                inputs = inputs.cuda()\n",
        "                target = target.cuda()\n",
        "            output = model(inputs)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            y_true.extend(target.tolist()) \n",
        "            y_pred.extend(pred.reshape(-1).tolist())\n",
        "        \n",
        "    return accuracy_score(y_true, y_pred)\n",
        "\n",
        "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
        "    x_axis = [i for i in range(len(losses))]\n",
        "    plt.plot(x_axis,losses)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.show()"
      ],
      "id": "09ef798a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ab4f94e"
      },
      "source": [
        "Now we can start the training loop for a number of epochs.\n",
        "\n",
        "If you run into VRAM limitations of your system, it might help to decrease the `batch_size` and initial learning rate accordingly. To keep this notebook's resource footprint small, we do not pre-load the whole dataset into DRAM. You should adjust your own training code to take advantage of multiprocessing and available memory for maximum performance."
      ],
      "id": "0ab4f94e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "040aec55"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ],
      "id": "040aec55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33feb873"
      },
      "source": [
        "batch_size = 1024\n",
        "num_epochs = 20\n",
        "\n",
        "data_loader_train = DataLoader(dataset, batch_size=batch_size, sampler=dataset.train_sampler)\n",
        "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler=dataset.test_sampler)\n",
        "\n",
        "if gpu is not None:\n",
        "    model = model.cuda()\n",
        "\n",
        "# loss criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if gpu is not None:\n",
        "    criterion = criterion.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
        "\n",
        "running_loss = []\n",
        "running_test_acc = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "        loss_epoch = train(model, data_loader_train, optimizer, criterion)\n",
        "        test_acc = test(model, data_loader_test)\n",
        "        print(\"Epoch %d: Training loss = %f, test accuracy = %f\" % (epoch, np.mean(loss_epoch), test_acc))\n",
        "        running_loss.append(loss_epoch)\n",
        "        running_test_acc.append(test_acc)\n",
        "        lr_scheduler.step()\n",
        "        \n",
        "print(\"Training Done!\")"
      ],
      "id": "33feb873",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9eb0a57"
      },
      "source": [
        "# Plot training loss over epochs\n",
        "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
        "display_loss_plot(loss_per_epoch)"
      ],
      "id": "a9eb0a57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a473eb5"
      },
      "source": [
        "# Plot test accuracy over epochs\n",
        "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
        "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
      ],
      "id": "9a473eb5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f16e8333"
      },
      "source": [
        "# Save the trained parameters to disk\n",
        "torch.save(model.state_dict(), \"model_trained.pth\")"
      ],
      "id": "f16e8333",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "867f2a90"
      },
      "source": [
        "# Load a Trained Model <a id='load_trained_model'></a>\n",
        "Alternatively, you can load the provided pre-trained model.\n",
        "It was trained for 20 epochs and reaches an overall accuracy of 56.0784%."
      ],
      "id": "867f2a90"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a09d086"
      },
      "source": [
        "from torch import nn\n",
        "import brevitas.nn as qnn\n",
        "from brevitas.quant import IntBias\n",
        "from brevitas.inject.enum import ScalingImplType\n",
        "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
        "\n",
        "#     Load Trained Model\n",
        "savefile=\"models/model.pth\"\n",
        "saved_state = torch.load(savefile, map_location=torch.device(\"cpu\"))\n",
        "model.load_state_dict(saved_state)\n",
        "if gpu is not None:\n",
        "    model = model.cuda()\n",
        "    print('GPU')\n",
        "    \n"
      ],
      "id": "9a09d086",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75a67a99"
      },
      "source": [
        "# Pruning <a id='prune'></a>\n",
        "\n",
        "*This is a very important step. Pruning helps in reducing the computational complextity of a model at the cost of some reduced accuracy.  \n",
        "\n",
        "NOTE: We will have to prune the model pre-trained model too."
      ],
      "id": "75a67a99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2554f06b"
      },
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "prune_percentage=0.2387\n",
        "print(prune_percentage)\n",
        "\n",
        "print(\"Prune Percentage @ {}%\".format(prune_percentage))\n",
        "\n",
        "\n",
        "index=[1, 4, 8, 13, 16, 20, 25, 27]\n",
        "\n",
        "parameters_to_prune=[]\n",
        "\n",
        "for i in index:    \n",
        "    parameters_to_prune.append((list(model.modules())[0][i], 'weight'))\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=prune_percentage,\n",
        ")\n",
        "print(\"Pruning Done!\")\n",
        "\n"
      ],
      "id": "2554f06b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10d0376b"
      },
      "source": [
        "# Evaluate the Accuracy <a id='evaluate_accuracy'></a>\n",
        "The following cells visualize the test accuracy across different modulations and signal-to-noise ratios. "
      ],
      "id": "10d0376b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da269970"
      },
      "source": [
        "# Set up a fresh test data loader\n",
        "batch_size = 1024\n",
        "dataset = radioml_18_dataset(dataset_path)\n",
        "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler=dataset.test_sampler)\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "id": "da269970",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2770fb55"
      },
      "source": [
        "# Run inference on validation data\n",
        "y_exp = np.empty((0))\n",
        "y_snr = np.empty((0))\n",
        "y_pred = np.empty((0,len(dataset.mod_classes)))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    for data in tqdm(data_loader_test, desc=\"Batches\"):\n",
        "        inputs, target, snr = data\n",
        "#             inputs=inputs.to(\"cuda:0\")\n",
        "        if gpu is not None:\n",
        "            inputs = inputs.cuda()\n",
        "        output = model(inputs)\n",
        "        y_pred = np.concatenate((y_pred,output.cpu()))\n",
        "        y_exp = np.concatenate((y_exp,target))\n",
        "        y_snr = np.concatenate((y_snr,snr))\n",
        "print(\"Inference Done!\")"
      ],
      "id": "2770fb55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bb15fc0"
      },
      "source": [
        "# Plot overall confusion matrix\n",
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=90)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "conf = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
        "confnorm = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
        "for i in range(len(y_exp)):\n",
        "    j = int(y_exp[i])\n",
        "    k = int(np.argmax(y_pred[i,:]))\n",
        "    conf[j,k] = conf[j,k] + 1\n",
        "for i in range(0,len(dataset.mod_classes)):\n",
        "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plot_confusion_matrix(confnorm, labels=dataset.mod_classes)\n",
        "\n",
        "cor = np.sum(np.diag(conf))\n",
        "ncor = np.sum(conf) - cor\n",
        "print(\"Overall Accuracy across all SNRs: %f\"%(cor / (cor+ncor)))"
      ],
      "id": "1bb15fc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cbe58b0"
      },
      "source": [
        "# Plot confusion matrices at 4 different SNRs\n",
        "snr_to_plot = [-20,-4,+4,+30]\n",
        "plt.figure(figsize=(16,10))\n",
        "acc = []\n",
        "for snr in dataset.snr_classes:\n",
        "    # extract classes @ SNR\n",
        "    indices_snr = (y_snr == snr).nonzero()\n",
        "    y_exp_i = y_exp[indices_snr]\n",
        "    y_pred_i = y_pred[indices_snr]\n",
        " \n",
        "    conf = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
        "    confnorm = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
        "    for i in range(len(y_exp_i)):\n",
        "        j = int(y_exp_i[i])\n",
        "        k = int(np.argmax(y_pred_i[i,:]))\n",
        "        conf[j,k] = conf[j,k] + 1\n",
        "    for i in range(0,len(dataset.mod_classes)):\n",
        "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        " \n",
        "    if snr in snr_to_plot:\n",
        "        plot, = np.where(snr_to_plot == snr)[0]\n",
        "        plt.subplot(221+plot)\n",
        "        plot_confusion_matrix(confnorm, labels=dataset.mod_classes, title=\"Confusion Matrix @ %d dB\"%(snr))\n",
        " \n",
        "    cor = np.sum(np.diag(conf))\n",
        "    ncor = np.sum(conf) - cor\n",
        "    acc.append(cor/(cor+ncor))"
      ],
      "id": "2cbe58b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46b39f85"
      },
      "source": [
        "# Plot accuracy over SNR\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(dataset.snr_classes, acc, marker='o')\n",
        "plt.xlabel(\"SNR [dB]\")\n",
        "plt.xlim([-20, 30])\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.title(\"Classification Accuracy over SNR\")\n",
        "plt.grid()\n",
        "plt.title(\"Classification Accuracy over SNR\");\n",
        "\n",
        "print(\"Accuracy @ highest SNR (+30 dB): %f\"%(acc[-1]))\n",
        "print(\"Accuracy overall: %f\"%(np.mean(acc)))"
      ],
      "id": "46b39f85",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a3eb097"
      },
      "source": [
        "# Plot accuracy per modulation\n",
        "accs = []\n",
        "for mod in range(24):\n",
        "    accs.append([])\n",
        "    for snr in dataset.snr_classes:\n",
        "        indices = ((y_exp == mod) & (y_snr == snr)).nonzero()\n",
        "        y_exp_i = y_exp[indices]\n",
        "        y_pred_i = y_pred[indices]\n",
        "        cor = np.count_nonzero(y_exp_i == np.argmax(y_pred_i, axis=1))\n",
        "        accs[mod].append(cor/len(y_exp_i))\n",
        "        \n",
        "# Plot accuracy-over-SNR curve\n",
        "plt.figure(figsize=(12,8))\n",
        "for mod in range(24):\n",
        "    if accs[mod][25] < 0.95 or accs[mod][0] > 0.1:\n",
        "        color = None\n",
        "    else:\n",
        "        color = \"black\"\n",
        "    plt.plot(dataset.snr_classes, accs[mod], label=str(mod) + \": \" + dataset.mod_classes[mod], color=color)\n",
        "plt.xlabel(\"SNR [dB]\")\n",
        "plt.xlim([-20, 30])\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.title(\"Accuracy breakdown\")\n",
        "plt.grid()\n",
        "plt.legend();"
      ],
      "id": "1a3eb097",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a432d880"
      },
      "source": [
        "# Evaluate the Inference Cost <a id='evaluate_inference_cost'></a>\n",
        "\n",
        "We evaluate the inference costof the model "
      ],
      "id": "a432d880"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b13daf28"
      },
      "source": [
        "from brevitas.export.onnx.generic.manager import BrevitasONNXManager\n",
        "\n",
        "export_onnx_path = \"models/ONNX/model_export.onnx\"\n",
        "final_onnx_path = \"models/ONNX/model_final.onnx\"\n",
        "cost_dict_path = \"models/ONNX/model_cost.json\""
      ],
      "id": "b13daf28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67fbd038"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(cost_dict_path, 'r') as f:\n",
        "    inference_cost_dict = json.load(f)\n",
        "\n",
        "bops = int(inference_cost_dict[\"total_bops\"])\n",
        "w_bits = int(inference_cost_dict[\"total_mem_w_bits\"])\n",
        "\n",
        "bops_baseline = 807699904\n",
        "w_bits_baseline = 1244936\n",
        "\n",
        "score = 0.5*(bops/bops_baseline) + 0.5*(w_bits/w_bits_baseline)\n",
        "print(\"Normalized inference cost score: %f\" % score)"
      ],
      "id": "67fbd038",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afb0ef84"
      },
      "source": [
        "inference_cost_dict"
      ],
      "id": "afb0ef84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0e5add"
      },
      "source": [
        ""
      ],
      "id": "bd0e5add",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af1914e7"
      },
      "source": [
        ""
      ],
      "id": "af1914e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09b5e65"
      },
      "source": [
        ""
      ],
      "id": "f09b5e65",
      "execution_count": null,
      "outputs": []
    }
  ]
}